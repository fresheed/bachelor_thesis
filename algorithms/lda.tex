
\subsection{Линейный дискриминантный анализ}

Метод \defn{линейного дискриминантного анализа (LDA)} применяется для того, чтобы снизить размерность исходных данных. Это осуществляется путём проекции на прямую, описываемую вектором $w$ в $N$-мерном пространстве. 

Прямая выбирается так, чтобы проекции элементов одного класса располагались близко друг к другу, а проекции элементов других классов были отдалены. 

\pastepic{Проекция двумерных точек разных классов на прямую}{design/lda_proj.png}{lda_proj}

Пусть $\mu_i$ - вектор средних величин признаков для класса $i$. Среднее значение спроецированных точек будет равно $\overline{m_i}=1/N_i\sum_j w^tx_j$, где $N_i$ - кол-во точек в классе, $x_j$ - элементы класса. Также введём разброс проекции: $\overline{s_i^2}=\sum (w^tx_j-\overline{m_i})^2$. Тогда \defn{линейный дискриминант Фишера} для двух классов определяется как максимум функции $J(w)=\dfrac{|\overline{m_1}-\overline{m_2}|^2}{\overline{s_1^2}+\overline{s_2^2}}$.

Определим вспомогательные матрицы: $S_i=\sum(x-\mu_i)(x-\mu_i)^t$, $S_w=S_1+S_2$ - матрицы разброса. Так как $\overline{s_i^2}=\sum (w^tx_j-\overline{m_i})^2$, то $\overline{s_i^2}=w^tS_iw$, $\overline{s_1^2}+\overline{s_2^2}=w^tS_ww$. Также введём $S_B=(\mu_1-\mu_2)*(\mu_1-\mu_2)^t$ - матрицу разброса между классами; $(\overline{m_1}-\overline{m_2})^2=w^tS_Bw$. Тогда $J(w)=\dfrac{w^tS_Bw}{w^tS_ww}$. 

Для нахождения максимума этой функции продифференцируем полученное выражение по $w$ и приравняем производную к нулю. После упрощения выражения получим: $S_w^{-1}S_Bw=Jw$. Таким образом, $w$ должен быть собственным значением для матрицы $S_w^{-1}S_B$. Так как $S_B=(\mu_1-\mu_2)*(\mu_1-\mu_2)^t$, то $w=S_w^{-1}(\mu_1-\mu_2)$. 

Полученная прямая $w$ является нормалью к гиперплоскости, которая оптимально разделяет проекции элементов двух классов. Процедура классификации заключается в сравнении значения проекции и некоторого порога; обычно его принимают равным $1/2(\mu_1+\mu_2)$.

Для выполнении мультиклассового распознавания применяется несколько техник. Во-первых, Rao\missing{ссылка} обобщил алгоритм LDA для проекции не на прямую, а на подпространство размерности $C-1$, где $C$ - число классов. Во-вторых, можно использовать техники "один-против-всех" и "один-против-одного" для объединения результатов бинарной классификации.


% @article{Rao1948,
%   added-at = {2011-03-14T01:06:24.000+0100},
%   author = {Rao, C. Radhakrishna},
%   biburl = {https://www.bibsonomy.org/bibtex/252fe52fa7db94bfefbf3899f3d7b5f59/lantiq},
%   file = {full paper:Rao1948.pdf:PDF},
%   groups = {public},
%   interhash = {5e6a4a1692a1a9f799bf2a49d833c695},
%   intrahash = {52fe52fa7db94bfefbf3899f3d7b5f59},
%   journal = {Journal of the Royal Statistical Society - Series B},
%   keywords = {statistics},
%   number = 2,
%   pages = {159-203},
%   timestamp = {2011-08-28T03:11:24.000+0200},
%   title = {The Utilization of Multiple Measurements in Problems of Biological Classification},
%   username = {lantiq},
%   volume = 10,
%   year = 1948
% }




% ссылки
% http://stu.alnam.ru/book_recob-45
% http://www.facweb.iitkgp.ernet.in/~sudeshna/courses/ML06/lda.pdf

