
\subsection{Линейный дискриминантный анализ}

Метод \defn{линейного дискриминантного анализа (LDA)} применяется для того, чтобы снизить размерность исходных данных. Это осуществляется путём проекции на прямую, описываемую вектором $w$ в $N$-мерном пространстве. 

Прямая выбирается так, чтобы проекции элементов одного класса располагались близко друг к другу, а проекции элементов других классов были отдалены (см. пример проекции на рис.\ref{fig:lda_proj}\cite{duda_lda}). 

\pastepic{Проекция двумерных точек разных классов на прямую}{design/lda_proj.png}{lda_proj}

Опишем алгоритм определения параметров этой прямой\cite{duda_lda}. Пусть $\mu_i$ - вектор средних величин признаков для класса $i$. Среднее значение спроецированных точек будет равно $\overline{m_i}=1/N_i\sum_j w^tx_j$, где $N_i$ - кол-во точек в классе, $x_j$ - элементы класса. Также введём разброс проекции: $\overline{s_i^2}=\sum (w^tx_j-\overline{m_i})^2$. Тогда \defn{линейный дискриминант Фишера} для двух классов определяется как максимум функции $J(w)=\dfrac{|\overline{m_1}-\overline{m_2}|^2}{\overline{s_1^2}+\overline{s_2^2}}$.

Определим вспомогательные матрицы: $S_i=\sum(x-\mu_i)(x-\mu_i)^t$, $S_w=S_1+S_2$ - матрицы разброса. Так как $\overline{s_i^2}=\sum (w^tx_j-\overline{m_i})^2$, то $\overline{s_i^2}=w^tS_iw$, $\overline{s_1^2}+\overline{s_2^2}=w^tS_ww$. Также введём $S_B=(\mu_1-\mu_2)*(\mu_1-\mu_2)^t$ - матрицу разброса между классами; $(\overline{m_1}-\overline{m_2})^2=w^tS_Bw$. Тогда $J(w)=\dfrac{w^tS_Bw}{w^tS_ww}$. 

Для нахождения максимума этой функции продифференцируем полученное выражение по $w$ и приравняем производную к нулю. После упрощения выражения получим: $S_w^{-1}S_Bw=Jw$. Таким образом, $w$ должен быть собственным вектором для матрицы $S_w^{-1}S_B$. Так как $S_B=(\mu_1-\mu_2)*(\mu_1-\mu_2)^t$, то $w=S_w^{-1}(\mu_1-\mu_2)$. \missing{как это доказать?}

Полученная прямая $w$ является нормалью к гиперплоскости, которая оптимально разделяет проекции элементов двух классов. Процедура классификации заключается в сравнении значения проекции и некоторого порога; обычно его принимают равным $1/2(\mu_1+\mu_2)$.

Для выполнении мультиклассового распознавания применяется несколько техник. Во-первых, Rao\cite{lda_multiclass} обобщил алгоритм LDA для проекции не на прямую, а на подпространство размерности $C-1$, где $C$ - число классов. Во-вторых, можно использовать техники "один-против-всех" и "один-против-одного" для объединения результатов бинарной классификации.



% ссылки
% http://stu.alnam.ru/book_recob-45
% http://www.facweb.iitkgp.ernet.in/~sudeshna/courses/ML06/lda.pdf

