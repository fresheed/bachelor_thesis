\subsection{Cкрытые марковские модели}

Дискретная марковская модель описывает систему, которая может в каждый данный дискретный момент времени находиться в одном из состояний $V=\{v_1...v_M\}$. Переход из одного состояния в другое зависит только от текущего состояния; таким образом, модель описывается матрицей $A: a_{ij}=P(v_i \to v_j)$. Это - наблюдаемая марковская модель: состояние системы является наблюдаемой величиной. 

Более общим и практичным подходом является аппарат \defn{скрытых марковских моделей} (СММ) - обобщение описанной концепции. В нём наблюдаемые события $v_k$ являются некоторой вероятностной функцией текущего состояния $s_j$, что описывается матрицей $B: b_j(k)=P[v_k | s_j]$. Кроме того, задаётся распределение вероятностей начального состояния $\Pi: \pi_i=P[q_1=s_i]$. 

Можно использовать СММ для моделирования временных рядов. Применительно к решаемой задаче наблюдаемые события $v_k$ - векторы-элементы временного ряда. Если удастся задать параметры модели так, чтобы последовательность наблюдаемых событий соответствовала данному временному ряду, то эти параметры можно будет использовать в качестве признаков для дальнейшей классификации.

Для нахождения оптимальных (максимизирующих вероятность наблюдения требуемой последовательности) параметров СММ используется \defn{алгоритм Баума-Велша}, также известны как алгоритм EM (Expectation Minimization). Пусть $O_1..O_t$ - последовательность наблюдаемых состояний, а $Q_1..Q_t$ - последовательность скрытых состояний СММ. Вводятся следующие выражения:
\begin{itemize}
\item $\alpha_t(i)=P(O_1, ... O_t , Q_t=i)$ - прямая переменная
\item $\beta_t(i)=P(O_{t+1}, ... O_T , Q_t=i)$ - обратная переменная
\end{itemize}
Для их вычисления используются процедуры прямого и обратного хода соответственно \cite{hmm_review}. Они показывают для выбранных момента времени и скрытого состояния, какова вероятность появления наблюдаемой последовательности до и после момента $t$ соответственно. 

На их основе вводятся также:
\begin{itemize}
\item $\gamma_t(i)=P(q_t=i | O)=\dfrac{\alpha_t(i)\beta_t(i)}{\sum\limits_k^N\alpha_t(k)\beta_t(k)}$ - вероятность нахождения в $i$ состоянии в момент времени $t$. Если эту величину просуммировать по всем $t$, то результат можно рассмотреть как ожидаемое количество переходов из состояния $i$
\item $\varepsilon_t(i,j)=P(q_t=i, q_{t+1}=j | O)=\dfrac{\alpha_t(i)a_{ij}b_j(O_{t+1})\beta_{t+1}(i)}{\sum\limits_u^N\sum\limits_v^N\alpha_t(u)a_{uv}b_v(O_{t+1})\beta_{t+1}(v)}$ - вероятность перехода из $i$ в $j$ в момент времени $t$. Если эту величину просуммировать по всем $t$, то результат можно рассмотреть как ожидаемое количество переходов из состояния $i$ в $j$
\end{itemize}

На основе этих формул можно произвести переоценку параметров $\pi, A, B$ и рассмотреть их смысл с точки зрения частоты переходов между состояниями:

\begin{itemize}
\item $\overline{\pi_i}=\gamma_1(i)$ - ожидаемое число переходов из $i$ в момент $t=1$
\item $\overline{a_{ij}}=\dfrac{\sum\limits_t^T\varepsilon_t(i,j)}{\sum\limits_t^T\gamma_t(i)}$ - ожидаемое число переходов из $i$ в $j$
\item $\overline{b_{j}(k)}=\dfrac{\sum\limits_t^T\gamma_t(i)*b_j(k)}{\sum\limits_t^T\gamma_t(i)}$ - ожидаемое число переходов из $i$ при наблюдении $k$
\end{itemize}

Баумом и его коллегами было показано, что этот алгоритм сходится к локальному оптимуму значений параметров \cite{hmm_conv_proof}.
