\subsection{Архитектура системы обучения моделей}

Задача системы обучения - проведение экспериментов с разными алгоритмами выделения признаков и классификации, а также подготовка файлов с параметрами обученных моделей.

Общий ход выполнения эксперимента задан в модуле \code{experiments.run\_experiment}. 

\begin{enumerate}
\item В зависимости от переданных аргументов из всего набора доступных алгоритмов выбирается некоторое подмножество. Это обусловлено тем, что при локальной отладке запуск всех алгоритмов занимает слишком большое время, и удобно выбрать только один из них. Кроме того, на сервере Travis CI (см. раздел про непрерывную интеграцию) установлен лимит времени в 50 минут на выполнение всех операций. При использовании кросс-валидации и переборе всех гиперпараметров время выполнения значительно превышает этот лимит, поэтому необходимо указывать подмножество наиболее важных алгоритмов, которые будут запускаться на сервере
\item Алгоритмы выделения признаков и классификации попарно комбинируются во всех различных сочетаниях. Таким образом, происходит исследование совместного функционирования этих алгоритмов
\item Производится загрузка и предобработка логов (см. далее)
\item Для каждой из ранее выбранной пар алгоритмов выполняется эксперимент с загруженными логами. В качестве результата возвращается матрица ошибок, рассчитанная при оптимальных значениях гиперпараметров на тестовой выборке, и оптимальные значения параметров модели и гиперпараметров алгоритма
\item Результаты сортируются по убыванию F-оценки (она же используется при кросс-валидации); таким образом, наглядно отображаются наиболее перспективные алгоритмы
\item Параметры классификаторов экспортируются в файлы и загружаются в хранилище Dropbox
% \missing{доработать алгоритм выгрузки параметров!}
\end{enumerate}

Рассмотрим подробнее этап загрузки логов:

\begin{enumerate}
\setcounter{enumi}{0}
\item Предварительный этап - преобразование бинарных файлов в текстовый формат. Как было указано ранее, в Android-приложении логи преобразуются в бинарный формат и отправляются в хранилище Dropbox. Чтобы преобразовать их в вид, понятный пакету pandas, наиболее целесообразно воспользоваться тем же модулем, которым было произведено сжатие. Для этого был написан небольшой скрипт на Groovy, который импортирует библиотеку javacommon и с её помощью сохраняет логи в текстовые файлы. Сохранение производится в CSV-файл с именем, в котором указан целевой класс. Этот этап выполняется вручную для обеспечения тщательного контроля данных, которые используются в экспериментах.
\item Модулю загрузки логов передаётся путь до каталога с файлами. Далее все найденные файлы используются для создания объектов \code{DataFrame} пакета pandas. Эти объекты представляют собой обёртку над многомерными массивами с возможностью индексации по временным меткам и другими дополнительными возможностями
\item Так как временные метки в "сырых" логах распределены неравномерно, то для корректного выделения признаков данные необходимо преобразовать так, чтобы временные метки были распределены с одинаковым шагом. Это выполняется усреднением точек, попадающих в один временной интервал. В результате экспериментов было установлено, что интервал в 100 мс даёт достаточно данных для дальнейшей обработки
\item Наконец, логи разбиваются на промежутки определённой длины. Это обусловлено тем, что при обработке в реальном времени классификатор должен реагировать достаточно быстро, и из-за слишком длинных логи отклик приложения будет долгим. Было решено использовать логи длиной в 1 секунду. Кроме того, удаляется по секунде в начале и в конце исходных логов, так как в это время обычно происходит подготовка к упражнению
\end{enumerate}

Ход эксперимента заключается в следующем:

\begin{enumerate}
\item Создаются 5 подвыборок для выполнения кросс-валидации, а также выделяется тестовая выборка
\item По указанным алгоритмам выделения признаков и классификации создаётся объект \code{Pipeline} пакета sklearn. Это вспомогательный объект, имеющий тот же интерфейс, что и обычные классификаторы. Здесь отметим, что классификаторы в sklearn имеют метод \code{fit}, который производит оптимизацию параметров модели. \code{Pipeline} при вызове этого метода оптимизирует все включённые в него модели, что упрощает дальнейшее выполнение эксперимента
\item Полученный \code{Pipeline} передаётся в конструктор объекту \code{GridSearchCV}. При вызове метода \code{fit} на нём производится оптимизация гиперпараметров включённых в него моделей. В качестве метрики качества используется F-мера с macro-усреднением метрик отдельных классов
\item Благодаря последовательной инкапсуляции алгоритмов друг в друга процедура обучения в эксперименте сводится к единственному вызову \code{fit}
\item Оценивается качество работы алгоритма на тестовой выборке
\item В качестве результата эксперимента возвращаются матрица ошибок и набор оптимальных параметров
\end{enumerate}

Базовым для классов-выделителей признаков является интерфейс \code{BaseEstimator}, предоставляемый sklearn. Для объединения всех реализуемых алгоритмов был введён класс \code{LogFeatureExtractor}, реализующий этот интерфейс. Объект этого класса вызывает для каждого полученного лога абстрактный метод \code{extract\_item\_features}, который реализуется конкретными подклассами для выделения признаков из лога. 

Все используемые в экспериментах классификаторы уже реализованы в sklearn, поэтому для их использования дополнительный код писать не пришлось. 

