\chapter{Проектирование системы распознавания движений}


\section{Структура системы распознавания}

Система распознавания состоит из нескольких блоков (рис. \ref{fig:system}):

\pastepic{Структура системы распознавания}{design/system.png}{system}

\begin{enumerate}
\item На умных часах происходит сбор данных с сенсоров и передача их в "сыром" виде на смартфон через установленное Bluetooth-соединение
\item В режиме обучения данные со смартфона отправляются на облачное хранилище, откуда далее попадают на стационарный компьютер
\item Обучение классификаторов происходит в офлайн-режиме
\item Модель с оптимальными параметрами загружается в приложение на смартфоне
\item В рабочем режиме данные подаются на вход обученному классификатору, и результат обработки показывается пользователю
\end{enumerate}


\section{Формальная постановка задачи}

В наиболее абстрактном виде задача описывается следующим образом. 

Временные ряды представлены конечными последовательностями значений: $S=s_1,s_2...s_n$, где $s_i$ - вектор значений $\left\{x_i,y_i,z_i\right\}$. Дан конечный набор классов $C=c_1,c_2...c_m$. Известно, что каждый ряд принадлежит одному и только одному классу. 

Для некоторого множества $L$ рядов известна принадлежность ряда к классу - такое множество назовём \defn{обучающей выборкой}. Также имеется множество $T$ рядов, принадлежность которых к классам неизвестна - это \defn{тестовая выборка}.

Необходимо по данной обучающей выборке классифицировать элементы тестовой выборки с максимальной точностью.

\section{Алгоритмы выделения признаков}

\defn{Признаком} называется результат измерения некоторой характеристики объекта. Формально  — это отображение $f: X\to D_f $, где D\_f — множество допустимых значений признака. Вектор $\bigl( f_1(x),\ldots,f_n(x) \bigr)$ называется \defn{признаковым описанием} объекта $x \in X$ \cite{features_def}. Матрица, состоящая из строк - признаковых описаний объектов, является стандартным видом представления исходных данных во многих алгоритмах машинного обучения. 

Несмотря на то, что временные ряды можно непосредственно рассматривать как наборы признаков, часто имеет смысл выделять другие признаки (выполнять т.н. \defn{feature extraction}) по разным причинам: несовпадение длин рядов, наличие шума и т.д.

\input{algorithms/ar.tex}

\input{algorithms/hmm.tex}

\input{algorithms/fft.tex}

\section{Алгоритмы классификации}

\input{algorithms/nn.tex}

\input{algorithms/nb.tex}

\input{algorithms/lda.tex}


\section{Алгоритмы, основанные на метриках расстояния}

Существует класс алгоритмов, основанных на вычислении расстояния (\defn{метрики}) между классифицируемыми объектами. 

\input{algorithms/dtw.tex}

\input{algorithms/knn.tex}


\section{Контроль качества распознавания}

\subsection{Метрики качества}

Для оценивания качества распознавания используется \defn{матрица ошибок (confusion matrix)}. Это квадратная матрица $C_{N*N}$, где $N$ - количество классов. При классификации элемента тестовой выборки инкрементируется $c_{ij}$, где $i$ - номер ожидаемого класса, $j$ - номер результирующего класса. Таким образом, при идеальной классификации $C$ должна иметь вид диагональной матрицы, элементы которой - размеры классов тестовой выборки. При наличии ошибок элементы вне диагонали становятся ненулевыми.

%\missing{привести пример confmat}
% $Phi_i=\mxthree{\phi_{xx}}{\phi_{yx}}{\phi_{zx}}{\phi_{xy}}{\phi_{yy}}{\phi_{zy}}{\phi_{xz}}{\phi_{yz}}{\phi_{zz}}$, 

Наиболее простой метрикой качества является \defn{accuracy} - отношение числа правильных ответов классификатора к общему числу элементов:

$acc=\dfrac{trace(C)}{sum(C)}$, где $trace(C)$ - след матрицы (сумма диагональных элементов), $sum(C)$ - сумма всех элементов.

Эта метрика неприменима для классов разных размеров. К примеру, если в первом классе 10 элементов, а во втором - 100, то, назначая любому элементу второй класс, получим $acc=\dfrac{100}{10+100}=0,909$. Это достаточно высокое значение показателя качества, но такое правило классификации не имеет практического смысла.

Решение этой проблемы - учёт каждого класса по отдельности. Рассмотрим задачу бинарной классификации - необходимо выяснить, принадлежит ли объект классу или нет. Для неё матрица ошибок имеет следующий вид:

$\mxtwo{True~Positive~(TP) }{False~Negative~(FN)}{False~Positive~(FP)}{True~Negative~(TN)}$

Введём следующие показатели:

\begin{itemize}
\item \defn{точность (precision)}: $P=\dfrac{TP}{TP+FP}$ - показывает, сколько объектов среди распознанных как принадлежащие к классу реально принадлежат eму
\item \defn{полнота (recall)}: $R=\dfrac{TP}{TP+FN}$ - показывает долю объектов класса, распознанных правильно
\end{itemize}

В реальных системах достичь максимальных значений обоих параметров невозможно: если распознавать большинство объектов как принадлежащие классу, то из-за роста False Positive будет снижаться точность; в обратном же случае из-за роста False Negative будет снижаться полнота. Поэтому необходимо соблюдать баланс между ними с помощью метрики, которая учитывает оба этих показателя. Одна из таких метрик - т.н. \defn{F-мера (F-score)}:

$F_\beta=(1+\beta^2)\dfrac{P*R}{\beta^2*P+R}$, где $\beta$ - вес точности в метрике. Обычно принимают $\beta=1$, тогда формула приобретает вид среднего гармонического точности и полноты. 

Для мультиклассового распознавания необходимо учитывать метрику, вычисленную для каждого класса в отдельности. Для F-меры есть следующие варианты\cite{sklearn_metric}:

\begin{itemize}
\item macro-усреднение: точность и полнота по всем классам вычисляется как среднее арифметическое этих показателей по отдельным классам
\item micro-усреднение: точность и полнота по всем классам вычисляются по стандартным формулам, где $TP, FP, FN$ - суммы соответствующих показателей по отдельным классам
\end{itemize}

\subsection{Выбор параметров модели и гиперпараметров}

На результат работы любого алгоритма машинного обучения влияют следующие факторы:

\begin{itemize}
\item параметры модели - веса в нейронной сети, средние и дисперсии в гауссовом байесовском классификаторе. Определяются в процессе обучения модели
\item \defn{гиперпараметры} - не зависят от процесса обучения: количество и состав скрытых слоёв нейронной сети, функции активации и т.д. Эти параметры задаются перед началом обучения
\end{itemize}

Выбор значений гиперпараметров в общем случае сводится к перебору их возможных значений. Наиболее простой способ сделать это - разделить всё множество известных объектов на подмножества:

\begin{itemize}
\item обучающая выборка - используется для настройки параметров модели
\item контрольная выборка - используется для выбора гиперпараметров. Так как метрика на контрольной выборке не зависит от результатов обучения, это позволяет избежать переобучения на обучающей выборке
\item тестовая выборка - используется для получения итогового значения метрик качества. Она необходима для того, чтобы выбор оптимальных гиперпараметров не приводил к переобучению на контрольной выборке
\end{itemize}

Такое разбиение приводит к тому, что в подмножествах оказывается слишком мало элементов. Чтобы избежать этого, используют \defn{кросс-валидацию}. Её алгоритм заключается в следующем:

\begin{enumerate}
\item всё множество объектов делится на обучающую и тестовую выборку
\item из обучающей выборки тем или иным образом выбирается $k$ подмножеств (\defn{fold}; могут пересекаться между собой)
\item процедура обучения и валидации выполняется $k$ раз, при этом в качестве собственно обучающего множества используются $k-1$ из полученных подмножеств, а контроль осуществляется по оставшемуся
\item контроль обучения осуществлятся усреднением $k$ результатов
\end{enumerate}

Такой алгоритм избавляет от необходимости использовать отдельную контрольную выборку. Недостаток - повышение вычислительных затрат из-за $k$ повторений процедуры обучения.

Существует несколько подходов к выбору подмножеств:

\begin{itemize}
\item разбиение на $k$ непересекающихся подмножеств (\defn{k-fold})
\item leave-one-out - подвид k-fold, где $k$ равно размеру обучающей выборки
\item leave-p-out - перебираются все варианты с $p$ элементами в контрольной выборке
\item случайное разбиение
\end{itemize}

Для повышения качества обучения подмножества могут быть стратифицированы - отношение размеров классов в них будут равны таковому во всей обучающей выборке.

% https://habrahabr.ru/company/ods/blog/328372/
% http://scikit-learn.org/stable/modules/model_evaluation.html#multiclass-and-multilabel-classification