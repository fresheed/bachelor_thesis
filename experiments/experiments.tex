
\chapter{Экспериментальное исследование}

\section{План исследования}

Для проверки реализованной системы проведём следующие эксперименты:

\begin{itemize}
\item Определение алгоритмов, дающих максимальную точность, и их параметров;
\item Определение того, как состав пользователей, для которых были записаны; тестовые данные, влияет на точность распознавания;
\item Проверка работы системы для случая, когда пользователь не участвовал в записи тестовых данных.
\end{itemize}


\section{Исходные данные для экспериментов}

В качестве исходных данных использовались записи активностей для четырёх пользователей. Числа обозначают суммарную длину записей данных акселерометра (в секундах), соответствующих этому типу активности и записанных данным пользователем

\begin{enumerate}
\item 65 - отжимания, 125 - ходьба, 90 - подтягивания, 96 - приседания; % егор
\item 18 - отжимания, 25 - ходьба, 22 - приседания; % макс
\item 24 - отжимания, 67 - ходьба, 28 - подтягивания, 33 - приседания; % миша
\item 21 - отжимания, 22 - ходьба, 16 - подтягивания, 18 - приседания. % андрей
\end{enumerate}

Таким образом, суммарно записано 128 секунд отжиманий, 239 секунд ходьбы, 134 секунды подтягиваний, 169 секунд приседаний.

В качестве тестового множества в каждом эксперименте отбиралось 30\% данных. Для кросс-валидации производилось разбиение оставшихся 70\% данных на 5 подвыборок.

% /home/fresheed/research/diploma/ActivityClassifier/parse/raw_logs//egor_logs.tar.gz: 38 log files, 376 chunks
% pushups: 65 chunks, % walk: 125 chunks, % pullups: 90 chunks, % sits: 96 chunks
% /home/fresheed/research/diploma/ActivityClassifier/parse/raw_logs/misha_logs.tar.gz: 103 log files, 152 chunks
% pushups: 24 chunks, % walk: 67 chunks, % pullups: 28 chunks, % sits: 33 chunks
% /home/fresheed/research/diploma/ActivityClassifier/parse/raw_logs//max_logs.tar.gz: 66 log files, 65 chunks
% pushups: 18 chunks, % walk: 25 chunks, % sits: 22 chunks, 
% /home/fresheed/research/diploma/ActivityClassifier/parse/raw_logs/andrew_logs.tar.gz: 6 log files, 77 chunks
% pushups: 21 chunks, % walk: 22 chunks, % pullups: 16 chunks, % sits: 18 chunks
% Total:
% pushups: 128 chunks, % walk: 239 chunks, % pullups: 134 chunks, % sits: 169 chunks
% train/test: 469/201


\section{Выполнение экспериментов}

Эксперименты запускались локально, т.к. на CI-сервере максимальное время сборки ограничено 50 минутами.

\subsection{Определение алгоритмов,  дающих максимальную точность, и их параметров}

Для выбора наиболее качественных алгоритмов была запущена процедура обучения и оценивания для всех возможных алгоритмов. Каждый из них - комбинация выделителя признаков и классификатора. Таким образом, были получены результаты для 27 алгоритмов. Приведём результаты на рис. \ref{fig:full_results}:

\pastepic{Результаты эксперимента}{experiments/output/1/results.png}{full_results}

Проанализируем результаты:
\begin{itemize}
\item Наивысшие показатели качества (свыше 0.9, см. табл. \ref{table:full_WaveletsFeaturesExtractor_MLPClassifier} - \ref{table:full_HMMABOutExtractor_MLPClassifier}) достигаются при использовании следующих признаков сигнала:  
  \begin{itemize}
  \item коэффициенты, получаемые при дискретном вейвлет-преобразовании;
  \item коэффициенты сплайнов, которые интерполируют сигнал;
  \item использование непосредственно значений временного ряда как признаков;
  \item матрица переходов, начальных вероятностей и средних значений выхода для скрытой марковской модели.
  \end{itemize}
\item Наивысшую точность даёт классификация на основе нейронных сетей, особенно в сочетании с вышеуказанными алгоритмами;
\item Ошибки классификации примерно одинаковы для различных классов, нельзя выделить какие-либо характерные ошибки;
\item Время обучения сильно зависит от сложности модели: для алгоритмов скрытых марковских моделей обучение занимало десятки секунд, для алгоритма DTW же, имеющего квадратичную сложность, обучение длилось 195 секунд;
\item Применение наивного гауссового классификатора значительно ускоряет обучение: например, для алгоритма с вейвлет-коэффициентами при использовании нейросети обучение длилось 7 секунд, а для гауссового классификатора - 0.7 секунд. Это объясняется тем, что при его применении перебор по элементам обучающей выборки происходит только один раз, а для нейросети - до схождения процесса обучения. Линейный дискриминантный анализ требует несколько большего времени, т.к. для определения параметров модели нужно выполнять относительно трудоёмкие матричные операции;
\item Время классификации на обученной модели также зависит от сложности алгоритма и примерно в 3-10 раз меньше длительности обучения. Так как обучение производится в офлайн-режиме, то более важной характеристикой алгоритма является именно эта величина.
\end{itemize}

По результатам исследования было принято решение в последующих экспериментах не задействовать алгоритмы, основанные на авторегрессии, DTW, а также использовании дисперсий выходных состояний скрытых марковских моделей: метрика качества для них имела относительно низкое значение, а время обучения и классификации, напротив, было значительным.

\subsection{Изучение влияния состава пользователей на качество распознавания}

Рассмотрим следующий вопрос: имеет ли смысл обучать систему работать с разными пользователями, или же стоит оптимизировать её под распознавание активности отдельного пользователя?

Для этого будем запускать обучение сначала для данных отдельных пользователей, затем для пар пользователей, для троек и, наконец, для всех пользователей.

Как было указано выше, в эксперименте не рассматриваются наиболее трудоёмкие и наименее эффективные алгоритмы.

Результаты эксперимента приведены на рис.\ref{fig:progression_results}. На данном графике для каждого из алгоритмов приведено по 4 горизонтальных столбца. Нижний соответствует обучению на отдельных пользователях, верхний - на всех 4 пользователях, промежуточные столбцы - для 2 и 3 соответственно. В столбцах разными цветами указан диапазон от минимальной точности, полученной в данной конфигурации, до максимальной.

\pastepic{Результаты эксперимента}{experiments/output/2/progression.png}{progression_results}

По графику видно, что при введении новых пользователей в обучающее множество в большинстве случаев качество распознавания ухудшается - точность уменьшается на величину до 0.2. Это объясняется тем, что при работе с одним пользователем система может научиться распознавать характерные особенности его движений, тогда как при наличии нескольких пользователей эти особенности сглаживаются.

Отметим, что лучшие алгоритмы, выбранные в предыдущем эксперименте, достаточно устойчивы к введению новых пользователей - их точность снижается незначительно. 

Наконец, стоит отметить, что в большинстве случаев с увеличением числа пользователей в обучающей выборке уменьшается разброс показателей качества. Это тоже связано со сглаживанием особенностей движений отдельных пользователей.

\subsection{Изучение влияния отсутствия пользователя в обучающей выборке}

Разрабатываемая система должна быть готова к использованию сразу после установки. Если при этом загрузить и установить её может любой желающий, то необходимо обеспечить приемлемое качество распознавания не только для тех пользователей, для которых производилось обучение, но и для любых других.

Проведём эксперимент, аналогичный предыдущему: будем запускать обучение сначала на данных отдельных пользователей, затем для пар пользователей и, наконец, для трёх пользователей. Оставшийся пользователь не будет участвовать в обучении, и на нём будет проверяться работоспособность системы.

Результаты эксперимента приведены на рис. \ref{fig:progression_unknown_results}.

\pastepic{Результаты эксперимента}{experiments/output/3/progression.png}{progression_unknown_results}

Заметно отличие от предыдущего эксперимента: алгоритмы, использующие нейронную сеть для классификации, показывают меньшую точность. В результате исследований было установлено, что имеет место \defn{переобучение (overfit)} - явление, при котором построенная модель находит закономерности, представленные в обучающей выборке и отсутствующие в тестовой. Были произведены попытки избежать переобучения (варьирование структуры сети, использование других алгоритмов обучения, введение раннего останова и т.д.), но ни один из этих методов не решил проблему.

С другой стороны, алгоритмы, использующие наивный байесовский классификатор, показали достаточно высокую точность распознавания.

Ещё одно отличие от предыдущего эксперимента - с увеличением числа пользователей в обучающей выборке повышается качество распознавания: разброс в точности значительно снижается, повышается минимальная точность для всех алгоритмов. В данном случае явление сглаживания особенностей движения пользователей является плюсом: для распознавания движений нового пользователя предпочтительно использовать общие их закономерности, а не особенности пользователей обучающей выборки.

Максимальная точность достигается при использовании вейвлет-преобразования и наивного байесовского классификатора (табл. \ref{table:best_partial_result}):

\input{experiments/output/3/best.tex}

\section{Итоговое сравнение алгоритмов}

Изученные алгоритмы различаются, в первую очередь, точностью классификации, которая достигается с их применением. Однако, учитывая то, что распознавание производится в реальном времени, следует учитывать также время исполнения алгоритма; некоторые алгоритмы неприменимы в реальных условиях, потому что выполняются слишком долго.

Условно исследованные алгоритмы классификации можно поделить на работающие с признаковым описанием и с метрикой в пространстве объектов. Среди последних был исследован только алгоритм динамического преобразования временной шкалы (DTW). Установлено, что из-за излишней длительности преобразования его нельзя применять в режиме реального времени. Точность распознавания, получаемая с его помощью, не очень высокая - около 70\%. Скорее всего, это связано с тем, что из сигнала не удалялись шумы, и алгоритм DTW выдавал не оптимальный путь преобразования. Метрика, получаемая с помощью DTW, в дальнейшем использовалась в алгоритме классификации методом ближайших соседей.

Для выделения признаков может использоваться временное или частотное представление сигнала. Для получения признаков из временной области использовались:
\begin{itemize}
\item модели временных рядов. В качестве признаков использовались коэффициенты уравнений, описывающих сигнал. Данные методы можно считать наименее подходящими к данной задаче: точность была одной из самых низких, а время распознавания - достаточно большим. Низкую точность распознавания можно объяснить тем, что временные ряды были нестационарными - их характеристики менялись со временем, а модели временных рядов ориентированы на работу со стационарными процессами;
\item скрытые марковские модели. В качестве признаков использовались либо коэффициенты матриц, описывающих модель, либо параметры распределений, описывающих выходные (наблюдаемые) состояния. Первый метод давал достаточно высокую точность, но требовал длительного обучения и классификации. Это можно объяснить тем, что алгоритм Баума-Велша, используемый для построения модели, имеет сложность $O(T*N^2)$ ($T$ - число наблюдений, $N$ - число состояний) из-за применения процедур прямого и обратного хода, и его необходимо применять для каждого временного ряда;
\item аппроксимация сигнала сплайнами. В качестве признаков использовались оптимальные коэффициенты сплайнов. Это достаточно быстрый алгоритм, так как вычисление коэффициентов сплайнов требует только решения линейной системы уравнений. Недостаток - классифицируемые ряды должны иметь одинаковую длину для того, чтобы сплайны покрывали один и тот же интервал значений
\end{itemize}

В частотной области использовались методы, основанные на преобразовании Фурье:
\begin{itemize}
\item непосредственное использование коэффициентов Фурье. Недостаток метода состоит в том, что он плохо обрабатывает нестационарные сигналы;
\item оконное преобразование Фурье. Позволяет решить проблему нестационарных сигналов;
\item вейвлет-преобразование даёт наилучший результат среди это группы методов благодаря динамическому изменению масштабирования временной и частотной шкал - это позволяет найти в сигнале как низкочастотные, так и высокочастотные составляющие;
\item аппроксимация спектра сплайнами. Этог метод сходен с аппроксимацией сигнала
\end{itemize}

Эти алгоритмы выполняются достаточно быстро: БПФ имеет сложность $O(N*logN)$, дискретное вейвлет-преобразование в простых случаях имеет сложность $O(N)$. Общий недостаток этих методов - необходимость соблюдения одной и той же длины сигналов для того, чтобы коэффициенты Фурье соответствовали одним и тем же частотам.

Среди алгоритмов классификации использовались нейронные сети, наивный байесовский классификатор и линейный дискриминантный анализ. Нейронные сети дают наилучшие результаты, если пользователь участвовал в создании обучающей выборки; иначе возникает проблема переобучения - так проявляется свойство нейронных сетей запоминать характерные особенности объектов выборки. Также из-за сложной структуры нейронных сетей их обучение занимает значительно большее время. 

Наивный байесовский классификатор хорошо применим в случае отсутствия пользователя в обучающей выборке. Кроме того, он быстро обучается благодаря более простому алгоритму.

Было также исследовано применение линейного дискриминантного анализа для классификации. Так как в результате его применения размерность данных сводится к единичной, то полученных признаков бывает недостаточно для корректной классификации. Поэтому результирующая точность этого алгоритма чуть ниже, чем для байесовского классификатора.

Точнее всего распознаётся ходьба, хуже всего - отжимания. Это можно объяснить тем, что в ходьбе легко определяется периодическая составляющая, а при отжиманиях рука практически не совершает движений.

