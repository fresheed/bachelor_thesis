
\chapter{Экспериментальное исследование}

\section{План исследования}

Для проверки реализованной системы эксперименталь установить следующие значения:

\begin{itemize}
\item Максимально достижимая точность распознавания
\item Алгоритмы и их параметры, дающие максимальную точность
\item Временные параметры алгоритмов
\end{itemize}


\section{Исходные данные для экспериментов}

В качестве исходных данных использовались записи активностей для трёх пользователей. Числа обозначают суммарную длину записей данных акселерометра (в секундах), соответствующих этому типу активности и записанных данным пользователем

\begin{enumerate}
\item 65 - отжимания, 125 - ходьба, 90 - подтягивания, 96 - приседания % я
\item 19 - отжимания, 22 - ходьба, 22 - приседания % макс
\item 15 - отжимания, 46 - ходьба, 15 - подтягивания, 20 - приседания % миша
\end{enumerate}

В качестве тестового множества отбиралось 30\% данных.


\section{Выполнение экспериментов}

Эксперимент для всех возможных сочетаний выделителей признаков и классификаторов был запущен локально, т.к. на CI-сервере максимальное время сборки ограничено 50 минутами. Результаты отсортированы по убыванию метрики качества.

Полные результаты эксперимента приведены в Прил. А. Приведём результаты для алгоритмов, давших наилучшие показатели качества:

\input{experiments/top_results.tex}

\section{Выбор наиболее качественных алгоритмов}

Для распознавания имеет смысл выбирать алгоритмы, дающие наиболее высокую точность.
Поэтому для использования в клиентском приложении были выбраны следующие алгоритмы выделения признаков:

\begin{itemize}
\item коэффициенты, получаемые при дискретном вейвлет-преобразовании
\item коэффициенты сплайнов, которые интерполируют сигнал
\item использование непосредственно значений временного ряда как признаков
\item матрица переходов, начальных вероятностей и средних значений выхода для скрытой марковской модели
\end{itemize}

В качестве алгоритма классификации используется только нейронная сеть - самые точные алгоритмы используют именно её.


\section{Анализ скорости выполнения}

Так как обучение производится в офлайн-режиме, то время обучения не имеет значения. Более важным является время выполнения классификации на обученной модели. Оно оценивалось по выполнении классификации на всей тестовой выборке.

Наиболее быстрые алгоритмы выделения признаков - аппроксимация сплайнами и использование значений ряда. Самые медленные - DTW, марковские модели и методы авторегрессии. Также на скорость выполнения влияет алгоритм классификации. Видно, что самым быстрым является наивный байесовский классификатор, самым медленным - нейронные сети.


% \subsection{Влияние числа участников - источников логов}

% Так как дообучения системы в данной реализации не предусматривается, модели должны быть обучены заранее. При этом конечный пользователь, скорее всего, не будет одним из тех, кто записывал исходные логи. Поэтому необходимо исследовать, насколько влияет число изначальных участников на качество конечного распознавания.

% Сначала обучим систему на одном человеке и проверим на другом:
% \begin{verbatim}
% 0: Experiment: HMMABOutExtractor -> MLPClassifier
% Confusion for ['pullups' 'pushups' 'sits' 'walk']:
% [[11  0  0  4]
%  [ 1 14  0  0]
%  [ 0  0 11  9]
%  [ 3 16  0 27]]
% Accuracy: 0.656250
% F1 score: 0.673285
% Score time: 6.849635 seconds

% 1: Experiment: WaveletsFeaturesExtractor -> MLPClassifier
% Confusion for ['pullups' 'pushups' 'sits' 'walk']:
% [[11  0  0  4]
%  [ 0  8  6  1]
%  [ 0  1 12  7]
%  [ 0  4 15 27]]
% Accuracy: 0.604167
% F1 score: 0.626427
% Best params: {'transformer__wavelet_type': 'rbio3.1'}
% Score time: 0.321736 seconds

% 2: Experiment: RawExtractor -> MLPClassifier
% Confusion for ['pullups' 'pushups' 'sits' 'walk']:
% [[11  0  0  4]
%  [ 1  9  5  0]
%  [ 0  0 11  9]
%  [ 0  7 12 27]]
% Accuracy: 0.604167
% F1 score: 0.620425
% Score time: 0.165004 seconds

% 3: Experiment: SignalInterpolator -> MLPClassifier
% Confusion for ['pullups' 'pushups' 'sits' 'walk']:
% [[11  0  0  4]
%  [ 0  9  5  1]
%  [ 0  0 10 10]
%  [ 2  7 10 27]]
% Accuracy: 0.593750
% F1 score: 0.606110
% Score time: 0.290232 seconds

% 4: Experiment: STFTCoeffsExtractor -> MLPClassifier
% Confusion for ['pullups' 'pushups' 'sits' 'walk']:
% [[ 5  6  0  4]
%  [ 6  4  5  0]
%  [ 0  1  8 11]
%  [ 0 10  3 33]]
% Accuracy: 0.520833
% F1 score: 0.438352
% Score time: 0.471020 seconds
% \end{verbatim}

% Теперь обучим систему на двух людях и проверим на третьем:

% \begin{verbatim}

% \end{verbatim}


\section{Итоговое сравнение алгоритмов}

Изученные алгоритмы различаются, в первую очередь, точностью классификации, которая достигается с их применением. Однако, учитывая то, что распознавание производится в реальном времени, следует учитывать также время исполнения алгоритма; некоторые алгоритмы неприменимы в реальных условиях, потому что выполняются слишком долго.

Условно исследованные алгоритмы классификации можно поделить на работающие с признаковым описанием и с метрикой в пространстве объектов. Среди последних был исследован только алгоритм динамического преобразования временной шкалы (DTW). Несмотря на то, что он давал достаточно высокую точность, из-за большого времени преобразования его нельзя применятоь в режиме реального времени. Тем не менее, он применим для обработки данных после окончания тренировки. Метрика, получаемая с помощью DTW, в дальнейшем использовалась в алгоритме классификации методом ближайших соседей.

Для выделения признаков может использоваться временное или частотное представление сигнала. Для получения признаков из временной области использовались:
\begin{itemize}
\item методы авторегрессии. В качестве признаков использовались коэффициенты уравнений, описывающих сигнал. Данные методы можно считать наименее подходящими к данной задаче: точность была одной из самых низких, а время распознавания - достаточно большим
\item скрытые марковские модели. В качестве признаков использовались коэффициенты матриц, описывающих модель, а также параметры распределений, описывающих выходные (наблюдаемые) состояния. Точность была достаточно высокой, время обучения - достаточно большим
\item аппроксимация сигнала сплайнами. Признаки - коэффициенты сплайнов. Достаточно быстрый алгоритм, дающий очень высокую точность. Недостаток - классифицируемые объекты должны иметь одинаковую длину
\end{itemize}

В частотной области использовались методы, основанные на преобразовании Фурье:
\begin{itemize}
\item непосредственное использование коэффициентов Фурье
\item оконное преобразование Фурье (признаки - последовательность групп коэффициентов, полученных для каждого из положений окна)
\item вейвлет-преобразование (аналогично предыдущему)
\item аппроксимация спектра сплайнами
\end{itemize}

Частотные методы чаще показывали более высокую точность и малое время работы, чем временные методы, поэтому их можно считать более перспективными. Общий недостаток - необходимость соблюдения одной и той же длины сигналов для того, чтобы коэффициенты Фурье соответствовали одним и тем же частотам.

Среди алгоритмов классификации использовались нейронные сети, наивный байесовский классификатор и линейный дискриминантный анализ. Наиболее высокую точность давали нейронные сети, наименьшее время работы - байесовский классификатор.

Точнее всего распознаётся ходьба, хуже всего - отжимания. Это можно объяснить тем, что в ходьбе легко определяется периодическая составляющая, а при отжиманиях рука практически не совершает движений.

