
\chapter{Экспериментальное исследование}

\section{План исследования}

Для проверки реализованной системы было поставлено несколько экспериментов:

\begin{itemize}
\item Выбор алгоритма, наиболее точно распознающего активности, и подбор его параметров
\item Установление скорости работы алгоритмов
% \item Изучение влияния количества людей, логи от которых попали в обучающую выборку, на качество распознавания \missing{переформулировать}
% \item Изучение влияния размера обучающей выборки на качество распознавания
\end{itemize}


\section{Исходные данные для экспериментов}

В качестве исходных данных использовались логи, записанные для трёх пользователей. Числа обозначают суммарную длину логов (в секундах), соответствующих этому типу активности и записанных данным пользователем

\begin{enumerate}
\item 65 - отжимания, 125 - ходьба, 90 - подтягивания, 96 - приседания % я
\item 19 - отжимания, 22 - ходьба, 22 - приседания % макс
\item 15 - отжимания, 46 - ходьба, 15 - подтягивания, 20 - приседания % миша
\end{enumerate}

В качестве тестового множества отбиралось 30\% данных.


\section{Выполнение экспериментов}

\subsection{Выбор оптимальных алгоритмов}

\missing{результаты для ВСЕХ алгоритмов}

Как было указано ранее, выполнение всех экспериментов длится достаточно долго. Поэтому для дальнейшего исследования выбраны следующие алгоритмы выделения признаков:

\begin{itemize}
\item матрица переходов, начальных вероятностей и средних значений выхода для скрытой марковской модели
\item использование непосредственно значений временного ряда как признаков
\item коэффициенты, получаемые при дискретном вейвлет-преобразовании
\item коэффициенты сплайнов, которые интерполируют сигнал
\end{itemize}

В качестве алгоритма классификации используется только нейронная сеть - самые точные алгоритмы используют именно её.

Для этих алгоритмов получены следующие матрицы ошибок и метрики качества:

\begin{verbatim}
0: Experiment: HMMABOutExtractor -> MLPClassifier
Confusion for ['pullups' 'pushups' 'sits' 'walk']:
[[31  0  0  1]
 [ 4 18  0  7]
 [ 0  0 37  5]
 [ 0  3  1 55]]
Accuracy: 0.870370
F1 score: 0.859129
Score time: 4.844990 seconds

1: Experiment: RawExtractor -> MLPClassifier
Confusion for ['pullups' 'pushups' 'sits' 'walk']:
[[31  0  0  1]
 [ 5 18  0  6]
 [ 0  0 37  5]
 [ 1  1  3 54]]
Accuracy: 0.864198
F1 score: 0.853747
Score time: 0.074178 seconds

2: Experiment: WaveletsFeaturesExtractor -> MLPClassifier
Confusion for ['pullups' 'pushups' 'sits' 'walk']:
[[31  0  1  0]
 [ 5 21  1  2]
 [ 0  3 34  5]
 [ 0  3  3 53]]
Accuracy: 0.858025
F1 score: 0.848007
Score time: 0.271462 seconds

3: Experiment: SignalInterpolator -> MLPClassifier
Confusion for ['pullups' 'pushups' 'sits' 'walk']:
[[31  0  1  0]
 [ 5 20  1  3]
 [ 0  3 35  4]
 [ 2  2  2 53]]
Accuracy: 0.858025
F1 score: 0.845352
Score time: 0.114271 seconds
\end{verbatim}

Как видим, значения метрики отличаются незначительно. Точнее всего распознаётся ходьба, хуже всего - отжимания. 

% \subsection{Влияние числа участников - источников логов}

% Так как дообучения системы в данной реализации не предусматривается, модели должны быть обучены заранее. При этом конечный пользователь, скорее всего, не будет одним из тех, кто записывал исходные логи. Поэтому необходимо исследовать, насколько влияет число изначальных участников на качество конечного распознавания.

% Сначала обучим систему на одном человеке и проверим на другом:
% \begin{verbatim}
% 0: Experiment: HMMABOutExtractor -> MLPClassifier
% Confusion for ['pullups' 'pushups' 'sits' 'walk']:
% [[11  0  0  4]
%  [ 1 14  0  0]
%  [ 0  0 11  9]
%  [ 3 16  0 27]]
% Accuracy: 0.656250
% F1 score: 0.673285
% Score time: 6.849635 seconds

% 1: Experiment: WaveletsFeaturesExtractor -> MLPClassifier
% Confusion for ['pullups' 'pushups' 'sits' 'walk']:
% [[11  0  0  4]
%  [ 0  8  6  1]
%  [ 0  1 12  7]
%  [ 0  4 15 27]]
% Accuracy: 0.604167
% F1 score: 0.626427
% Best params: {'transformer__wavelet_type': 'rbio3.1'}
% Score time: 0.321736 seconds

% 2: Experiment: RawExtractor -> MLPClassifier
% Confusion for ['pullups' 'pushups' 'sits' 'walk']:
% [[11  0  0  4]
%  [ 1  9  5  0]
%  [ 0  0 11  9]
%  [ 0  7 12 27]]
% Accuracy: 0.604167
% F1 score: 0.620425
% Score time: 0.165004 seconds

% 3: Experiment: SignalInterpolator -> MLPClassifier
% Confusion for ['pullups' 'pushups' 'sits' 'walk']:
% [[11  0  0  4]
%  [ 0  9  5  1]
%  [ 0  0 10 10]
%  [ 2  7 10 27]]
% Accuracy: 0.593750
% F1 score: 0.606110
% Score time: 0.290232 seconds

% 4: Experiment: STFTCoeffsExtractor -> MLPClassifier
% Confusion for ['pullups' 'pushups' 'sits' 'walk']:
% [[ 5  6  0  4]
%  [ 6  4  5  0]
%  [ 0  1  8 11]
%  [ 0 10  3 33]]
% Accuracy: 0.520833
% F1 score: 0.438352
% Score time: 0.471020 seconds
% \end{verbatim}

% Теперь обучим систему на двух людях и проверим на третьем:

% \begin{verbatim}

% \end{verbatim}

\subsection{Установление скорости работы алгоритмов}

\missing{добавить цифры}


\section{Сравнение алгоритмов}

Изученные алгоритмы различаются, в первую очередь, точностью классификации, которая достигается с их применением. Однако, учитывая то, что распознавание производится в реальном времени, следует учитывать также время исполнения алгоритма; некоторые алгоритмы неприменимы в реальных условиях, потому что не удовлетворяют этому условию.

Условно исследованные алгоритмы классификации можно поделить на работающие с признаковым описанием и с метрикой в пространстве объектов. Среди последних был исследован только алгоритм динамического преобразования временной шкалы (DTW). Несмотря на то, что он давал достаточно высокую точность, из-за большого времени преобразования его нельзя применятоь в режиме реального времени. Тем не менее, он применим для обработки данных после окончания тренировки. Метрика, получаемая с помощью DTW, в дальнейшем использовалась в алгоритме классификации методом ближайших соседей.

Для выделения признаков может использоваться временное или частотное представление сигнала. Для получения признаков из временной области использовались:
\begin{itemize}
\item методы авторегрессии. В качестве признаков использовались коэффициенты уравнений, описывающих сигнал. Данные методы можно считать наименее подходящими к данной задаче: точность была одной из самых низких, а время распознавания - достаточно большим
\item скрытые марковские модели. В качестве признаков использовались коэффициенты матриц, описывающих модель, а также параметры распределений, описывающих выходные (наблюдаемые) состояния. Точность была достаточно высокой, время обучения - достаточно большим
\item аппроксимация сигнала сплайнами. Признаки - коэффициенты сплайнов. Достаточно быстрый алгоритм, дающий очень высокую точность. Недостаток - классифицируемые логи должны иметь одинаковую длину
\end{itemize}

В частотной области использовались методы, основанные на преобразовании Фурье:
\begin{itemize}
\item непосредственное использование коэффициентов Фурье
\item оконное преобразование Фурье (признаки - последовательность групп коэффициентов, полученных для каждого из положений окна)
\item вейвлет-преобразование (аналогично предыдущему)
\item аппроксимация спектра сплайнами
\end{itemize}

Все частотные методы показывали более высокую точность и малое время работы, чем временные методы, поэтому их можно считать более перспективными. Общий недостаток - необходимость соблюдения одной и той же длины сигналов для того, чтобы коэффициенты Фурье соответствовали одним и тем же частотам.

Среди алгоритмов классификации использовались нейронные сети, наивный байесовский классификатор и линейный дискриминантный анализ. Наиболее высокую точность давали нейронные сети, наименьшее время работы - байесовский классификатор.


